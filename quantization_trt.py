# é‡ä¸ºä»€ä¹ˆè¦æ¨¡å‹é‡åŒ–ï¼Ÿ
# ç®€å•è¯´ï¼šä¸ºäº†è®©æ¨¡å‹æ›´å°ã€æ›´å¿«ã€æ›´çœèµ„æºåœ°éƒ¨ç½²åˆ°å„ç§è®¾å¤‡ä¸Šï¼ˆå°¤å…¶æ˜¯è¾¹ç¼˜è®¾å¤‡ã€ç§»åŠ¨ç«¯ã€åµŒå…¥å¼è®¾å¤‡ç­‰ï¼‰

# ONNX Runtime å’Œ TensorRT éƒ½æ˜¯æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½²çš„æ¡†æ¶ã€‚
# ğŸ’» é€šç”¨ CPU / GPU éƒ¨ç½²	âœ… ONNX Runtime
# âš¡ æè‡´ GPU æ€§èƒ½ï¼ˆNVIDIA GPUï¼‰	âœ… TensorRT
# å¼€å‘åˆæœŸ / é€šç”¨éƒ¨ç½²ï¼š ç”¨ ONNX Runtimeï¼Œå®‰è£…å¿«ã€ç”¨æ³•ç®€å•ã€‚
# æ­£å¼éƒ¨ç½² / GPU æœåŠ¡ï¼š æŠŠ ONNX æ¨¡å‹è½¬æ¢ä¸º TensorRT Engineï¼ŒåŠ é€Ÿæ¨ç†ã€‚
# è¾¹ç¼˜è®¾å¤‡ï¼š å¯ç”¨ OpenVINOã€TensorRTï¼ˆJetsonï¼‰ã€TFLite ç­‰ã€‚



import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

TRT_LOGGER = trt.Logger(trt.Logger.INFO)

def build_int8_engine(onnx_file_path, engine_file_path, calibration_stream, input_shape):
    builder = trt.Builder(TRT_LOGGER)
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    parser = trt.OnnxParser(network, TRT_LOGGER)

    with open(onnx_file_path, 'rb') as model:
        if not parser.parse(model.read()):
            print('Failed to parse the ONNX file.')
            for error in range(parser.num_errors):
                print(parser.get_error(error))
            return None

    config = builder.create_builder_config()
    config.max_workspace_size = 1 << 30  # 1GB

    # INT8é‡åŒ–
    config.set_flag(trt.BuilderFlag.INT8)
    config.int8_calibrator = MyCalibrator(calibration_stream, input_shape)

    engine = builder.build_engine(network, config)
    with open(engine_file_path, "wb") as f:
        f.write(engine.serialize())
    print(f"INT8 TensorRT engine saved to {engine_file_path}")

# ä½ éœ€è¦å®ç°è‡ªå·±çš„æ ¡å‡†å™¨
class MyCalibrator(trt.IInt8EntropyCalibrator2):
    def __init__(self, calibration_stream, input_shape):
        trt.IInt8EntropyCalibrator2.__init__(self)
        self.stream = calibration_stream
        self.d_input = cuda.mem_alloc(trt.volume(input_shape) * trt.float32.itemsize)
        self.input_shape = input_shape

    def get_batch_size(self):
        return self.input_shape[0]

    def get_batch(self, names):
        try:
            data = next(self.stream)
            cuda.memcpy_htod(self.d_input, data)
            return [int(self.d_input)]
        except StopIteration:
            return None

    def read_calibration_cache(self):
        return None

    def write_calibration_cache(self, cache):
        pass

# ç¤ºä¾‹æ ¡å‡†æ•°æ®ç”Ÿæˆå™¨
def calibration_data_generator():
    # è¿™é‡Œéœ€è¦è¿”å›numpyæ•°ç»„ï¼Œå½¢çŠ¶ä¸ºinput_shape
    # ä¾‹å¦‚ï¼š(1, 3, 224, 224)
    import numpy as np
    for _ in range(10):
        yield np.random.random((1, 3, 224, 224)).astype(np.float32)

if __name__ == "__main__":
    onnx_path = "model.onnx"
    engine_path = "model_int8.engine"
    input_shape = (1, 3, 224, 224)
    build_int8_engine(onnx_path, engine_path, calibration_data_generator(), input_shape)